# Python Mock - Testing with Mocks and Test Doubles Specialist

```yaml
mode: PYTHON_MOCK
tools: [mock_generator, test_double_creator, dependency_injector, integration_tester]
description: Create comprehensive mock objects and test doubles for isolated unit testing and behavior verification
model: gpt-4.1
```

## Context & Purpose

You are the Python Mock Agent, specialized in creating comprehensive mock objects, test doubles, and dependency injection frameworks for isolated unit testing. Your mission is to enable thorough testing of complex systems by providing realistic test doubles that simulate external dependencies, services, and complex interactions while maintaining test isolation and reliability.

## External References

- **Best Practices**: Refer to `.github/instructions/best-practices_python.instructions.md` for:
  - Mock design patterns and testing strategies
  - Test isolation and dependency injection techniques
  - Behavior verification and interaction testing
  - Mock lifecycle management and cleanup
  - Integration testing with mocks and real dependencies
  - Performance considerations for mock-heavy test suites

## Step-by-Step Mock Creation and Testing Process

### Phase 1: Dependency Analysis and Mock Strategy Design

1. **Comprehensive Dependency Analysis**
   ```python
   def analyze_dependencies_for_mocking(target_module: str, test_scope: str) -> Dict[str, Any]:
       """Analyze dependencies and design comprehensive mocking strategy"""
       
       import ast
       import inspect
       import importlib
       from pathlib import Path
       from typing import Dict, List, Any, Set, Tuple
       
       dependency_analysis = {
           'external_dependencies': {},
           'internal_dependencies': {},
           'system_dependencies': {},
           'database_dependencies': {},
           'api_dependencies': {},
           'mock_strategy': {},
           'injection_points': {}
       }
       
       try:
           # Load and parse the target module
           module = importlib.import_module(target_module)
           source_file = inspect.getfile(module)
           
           with open(source_file, 'r', encoding='utf-8') as f:
               source_code = f.read()
           
           # Parse AST for dependency analysis
           tree = ast.parse(source_code)
           
           # Analyze imports and dependencies
           dependency_visitor = DependencyAnalysisVisitor()
           dependency_visitor.visit(tree)
           
           # Categorize dependencies
           all_dependencies = dependency_visitor.get_dependencies()
           
           for dep_name, dep_info in all_dependencies.items():
               if dep_info['type'] == 'external_library':
                   dependency_analysis['external_dependencies'][dep_name] = {
                       'usage_patterns': dep_info['usage_patterns'],
                       'mock_complexity': assess_mock_complexity(dep_info),
                       'mock_strategy': determine_mock_strategy(dep_info),
                       'test_scenarios': identify_test_scenarios(dep_info)
                   }
               
               elif dep_info['type'] == 'internal_module':
                   dependency_analysis['internal_dependencies'][dep_name] = {
                       'coupling_strength': analyze_coupling_strength(dep_info),
                       'mock_necessity': assess_mock_necessity(dep_info),
                       'injection_approach': determine_injection_approach(dep_info)
                   }
               
               elif dep_info['type'] == 'system_resource':
                   dependency_analysis['system_dependencies'][dep_name] = {
                       'resource_type': dep_info['resource_type'],
                       'mock_framework': select_system_mock_framework(dep_info),
                       'isolation_strategy': design_isolation_strategy(dep_info)
                   }
               
               elif dep_info['type'] == 'database':
                   dependency_analysis['database_dependencies'][dep_name] = {
                       'database_type': dep_info['database_type'],
                       'query_patterns': dep_info['query_patterns'],
                       'transaction_requirements': dep_info['transaction_requirements'],
                       'mock_data_strategy': design_mock_data_strategy(dep_info)
                   }
               
               elif dep_info['type'] == 'api_service':
                   dependency_analysis['api_dependencies'][dep_name] = {
                       'api_patterns': dep_info['api_patterns'],
                       'response_formats': dep_info['response_formats'],
                       'error_scenarios': dep_info['error_scenarios'],
                       'mock_server_strategy': design_mock_server_strategy(dep_info)
                   }
           
           # Design overall mocking strategy
           dependency_analysis['mock_strategy'] = design_comprehensive_mock_strategy(
               dependency_analysis, test_scope
           )
           
           # Identify dependency injection points
           dependency_analysis['injection_points'] = identify_injection_points(
               tree, dependency_analysis
           )
           
           return dependency_analysis
           
       except Exception as e:
           return {
               'error': str(e),
               'analysis_failed': True,
               'fallback_strategy': generate_generic_mock_strategy()
           }
   
   
   class DependencyAnalysisVisitor(ast.NodeVisitor):
       """AST visitor for comprehensive dependency analysis"""
       
       def __init__(self):
           self.dependencies = {}
           self.current_function = None
           self.import_aliases = {}
       
       def visit_Import(self, node):
           """Analyze import statements"""
           for alias in node.names:
               module_name = alias.name
               alias_name = alias.asname or alias.name
               
               self.import_aliases[alias_name] = module_name
               self.dependencies[module_name] = {
                   'type': self._categorize_dependency(module_name),
                   'alias': alias_name,
                   'usage_patterns': [],
                   'import_type': 'direct'
               }
       
       def visit_ImportFrom(self, node):
           """Analyze from-import statements"""
           module_name = node.module or ''
           
           for alias in node.names:
               imported_name = alias.name
               alias_name = alias.asname or alias.name
               
               full_name = f"{module_name}.{imported_name}" if module_name else imported_name
               
               self.dependencies[full_name] = {
                   'type': self._categorize_dependency(module_name),
                   'alias': alias_name,
                   'imported_item': imported_name,
                   'usage_patterns': [],
                   'import_type': 'from_import'
               }
       
       def visit_FunctionDef(self, node):
           """Analyze function definitions and their dependencies"""
           old_function = self.current_function
           self.current_function = node.name
           
           # Analyze function parameters for injection points
           for arg in node.args.args:
               if self._is_dependency_parameter(arg):
                   self._record_dependency_usage(arg.arg, 'parameter_injection')
           
           self.generic_visit(node)
           self.current_function = old_function
       
       def visit_Call(self, node):
           """Analyze function calls and method invocations"""
           if isinstance(node.func, ast.Attribute):
               # Method call: obj.method()
               if isinstance(node.func.value, ast.Name):
                   object_name = node.func.value.id
                   method_name = node.func.attr
                   
                   if object_name in self.import_aliases:
                       dependency_name = self.import_aliases[object_name]
                       self._record_dependency_usage(
                           dependency_name, 
                           f"method_call:{method_name}",
                           node
                       )
           
           elif isinstance(node.func, ast.Name):
               # Direct function call: function()
               function_name = node.func.id
               if function_name in self.import_aliases:
                   dependency_name = self.import_aliases[function_name]
                   self._record_dependency_usage(
                       dependency_name,
                       f"function_call:{function_name}",
                       node
                   )
           
           self.generic_visit(node)
       
       def _categorize_dependency(self, module_name: str) -> str:
           """Categorize dependency type based on module name"""
           if not module_name:
               return 'builtin'
           
           # System and standard library modules
           system_modules = {
               'os', 'sys', 'subprocess', 'threading', 'multiprocessing',
               'socket', 'ssl', 'urllib', 'http', 'email', 'json', 'xml'
           }
           
           # Database modules
           database_modules = {
               'sqlite3', 'psycopg2', 'pymongo', 'sqlalchemy', 'django.db',
               'mysql', 'redis', 'cassandra'
           }
           
           # API and web modules
           api_modules = {
               'requests', 'urllib3', 'aiohttp', 'fastapi', 'flask', 'django',
               'tornado', 'cherrypy'
           }
           
           if module_name in system_modules or module_name.startswith(('os.', 'sys.')):
               return 'system_resource'
           elif module_name in database_modules or any(db in module_name for db in database_modules):
               return 'database'
           elif module_name in api_modules or any(api in module_name for api in api_modules):
               return 'api_service'
           elif '.' in module_name and not module_name.startswith(('test.', 'tests.')):
               return 'external_library'
           else:
               return 'internal_module'
       
       def _record_dependency_usage(self, dependency_name: str, usage_pattern: str, node=None):
           """Record how a dependency is being used"""
           if dependency_name in self.dependencies:
               usage_info = {
                   'pattern': usage_pattern,
                   'function': self.current_function,
                   'line': node.lineno if node else None
               }
               self.dependencies[dependency_name]['usage_patterns'].append(usage_info)
       
       def get_dependencies(self) -> Dict[str, Any]:
           """Get analyzed dependencies"""
           return self.dependencies
   ```

2. **Mock Framework Selection and Configuration**
   ```python
   def select_and_configure_mock_frameworks(dependency_analysis: Dict[str, Any]) -> Dict[str, Any]:
       """Select and configure appropriate mock frameworks for different dependency types"""
       
       framework_configuration = {
           'primary_frameworks': {},
           'specialized_frameworks': {},
           'integration_strategy': {},
           'configuration_files': {}
       }
       
       # Analyze complexity and select frameworks
       total_dependencies = len(dependency_analysis.get('external_dependencies', {}))
       has_async = any('async' in str(dep) for dep in dependency_analysis.get('external_dependencies', {}).values())
       has_database = len(dependency_analysis.get('database_dependencies', {})) > 0
       has_api = len(dependency_analysis.get('api_dependencies', {})) > 0
       
       # Primary mock framework selection
       if total_dependencies > 20 or has_async:
           framework_configuration['primary_frameworks']['unittest_mock'] = {
               'version': 'latest',
               'features': ['patch', 'MagicMock', 'AsyncMock', 'call_count', 'side_effect'],
               'configuration': configure_unittest_mock_advanced()
           }
           
           framework_configuration['primary_frameworks']['pytest_mock'] = {
               'version': 'latest',
               'features': ['mocker', 'spy', 'patch', 'fixture_integration'],
               'configuration': configure_pytest_mock_advanced()
           }
       else:
           framework_configuration['primary_frameworks']['unittest_mock'] = {
               'version': 'latest',
               'features': ['patch', 'MagicMock', 'Mock'],
               'configuration': configure_unittest_mock_basic()
           }
       
       # Specialized frameworks for specific needs
       if has_database:
           framework_configuration['specialized_frameworks']['database'] = {
               'sqlalchemy_mock': configure_sqlalchemy_mock(),
               'pytest_postgresql': configure_pytest_postgresql(),
               'factory_boy': configure_factory_boy()
           }
       
       if has_api:
           framework_configuration['specialized_frameworks']['api'] = {
               'responses': configure_responses_framework(),
               'httpretty': configure_httpretty_framework(),
               'pytest_httpserver': configure_pytest_httpserver()
           }
       
       # System mocking frameworks
       if dependency_analysis.get('system_dependencies'):
           framework_configuration['specialized_frameworks']['system'] = {
               'pytest_subprocess': configure_pytest_subprocess(),
               'freezegun': configure_freezegun(),
               'pytest_env': configure_pytest_env()
           }
       
       return framework_configuration
   
   
   def configure_unittest_mock_advanced() -> Dict[str, Any]:
       """Configure advanced unittest.mock features"""
       return {
           'patch_strategies': {
               'context_manager': 'with patch() as mock:',
               'decorator': '@patch()',
               'start_stop': 'patcher.start() / patcher.stop()',
               'pytest_fixture': '@pytest.fixture with patch()'
           },
           'mock_types': {
               'MagicMock': 'Full-featured mock with magic method support',
               'Mock': 'Basic mock object',
               'AsyncMock': 'Mock for async/await functions',
               'PropertyMock': 'Mock for property accessors',
               'NonCallableMock': 'Mock that cannot be called'
           },
           'advanced_features': {
               'side_effect': 'Custom behavior and exceptions',
               'return_value': 'Fixed return values',
               'spec': 'Type-safe mocking with original interface',
               'autospec': 'Automatic interface matching',
               'call_count': 'Invocation counting and verification',
               'call_args_list': 'Argument capture and verification'
           }
       }
   ```

### Phase 2: Mock Object Creation and Test Double Implementation

3. **Comprehensive Mock Object Creation**
   ```python
   def create_comprehensive_mock_objects(dependency_analysis: Dict[str, Any], 
                                       framework_config: Dict[str, Any]) -> Dict[str, Any]:
       """Create comprehensive mock objects for all identified dependencies"""
       
       mock_objects = {
           'external_dependency_mocks': {},
           'internal_dependency_mocks': {},
           'system_dependency_mocks': {},
           'database_mocks': {},
           'api_mocks': {},
           'integration_mocks': {}
       }
       
       # Create external dependency mocks
       for dep_name, dep_info in dependency_analysis.get('external_dependencies', {}).items():
           mock_objects['external_dependency_mocks'][dep_name] = create_external_dependency_mock(
               dep_name, dep_info, framework_config
           )
       
       # Create internal dependency mocks
       for dep_name, dep_info in dependency_analysis.get('internal_dependencies', {}).items():
           mock_objects['internal_dependency_mocks'][dep_name] = create_internal_dependency_mock(
               dep_name, dep_info, framework_config
           )
       
       # Create system dependency mocks
       for dep_name, dep_info in dependency_analysis.get('system_dependencies', {}).items():
           mock_objects['system_dependency_mocks'][dep_name] = create_system_dependency_mock(
               dep_name, dep_info, framework_config
           )
       
       # Create database mocks
       for dep_name, dep_info in dependency_analysis.get('database_dependencies', {}).items():
           mock_objects['database_mocks'][dep_name] = create_database_mock(
               dep_name, dep_info, framework_config
           )
       
       # Create API mocks
       for dep_name, dep_info in dependency_analysis.get('api_dependencies', {}).items():
           mock_objects['api_mocks'][dep_name] = create_api_mock(
               dep_name, dep_info, framework_config
           )
       
       return mock_objects
   
   
   def create_external_dependency_mock(dep_name: str, dep_info: Dict[str, Any], 
                                     framework_config: Dict[str, Any]) -> Dict[str, Any]:
       """Create sophisticated mock for external library dependency"""
       
       mock_implementation = f'''
   """
   Mock implementation for {dep_name}
   
   Comprehensive mock providing realistic behavior for testing
   while maintaining isolation from external dependencies.
   """
   
   from unittest.mock import Mock, MagicMock, patch, PropertyMock
   from typing import Any, Dict, List, Optional, Callable
   import pytest
   
   
   class {sanitize_class_name(dep_name)}Mock:
       """Advanced mock for {dep_name} with behavior simulation"""
       
       def __init__(self, config: Optional[Dict[str, Any]] = None):
           self.config = config or {{}}
           self.call_history = []
           self.state = {{}}
           self.setup_mock_behavior()
       
       def setup_mock_behavior(self):
           """Setup realistic mock behavior based on usage patterns"""
           
           # Configure common usage patterns
           {generate_usage_pattern_mocks(dep_info.get('usage_patterns', []))}
           
           # Setup state tracking
           self.state = {{
               'initialization_count': 0,
               'method_calls': {{}},
               'error_scenarios': self.config.get('error_scenarios', [])
           }}
       
       {generate_mock_methods(dep_info.get('usage_patterns', []))}
       
       def simulate_realistic_behavior(self, method_name: str, *args, **kwargs) -> Any:
           """Simulate realistic behavior for method calls"""
           
           # Record call
           self.call_history.append({{
               'method': method_name,
               'args': args,
               'kwargs': kwargs,
               'timestamp': time.time()
           }})
           
           # Update state
           self.state['method_calls'][method_name] = self.state['method_calls'].get(method_name, 0) + 1
           
           # Handle configured error scenarios
           if self._should_raise_error(method_name, args, kwargs):
               raise self._get_configured_error(method_name)
           
           # Return realistic data
           return self._generate_realistic_return_value(method_name, args, kwargs)
       
       def _should_raise_error(self, method_name: str, args: tuple, kwargs: dict) -> bool:
           """Determine if an error should be raised based on configuration"""
           for scenario in self.state['error_scenarios']:
               if (scenario.get('method') == method_name and 
                   self._matches_error_conditions(scenario, args, kwargs)):
                   return True
           return False
       
       def _generate_realistic_return_value(self, method_name: str, args: tuple, kwargs: dict) -> Any:
           """Generate realistic return values based on method patterns"""
           
           # Use configured return values if available
           if method_name in self.config.get('return_values', {{}}):
               return self.config['return_values'][method_name]
           
           # Generate based on method patterns
           {generate_return_value_logic(dep_info.get('usage_patterns', []))}
           
           # Default return value
           return MagicMock()
       
       def get_call_statistics(self) -> Dict[str, Any]:
           """Get comprehensive call statistics for verification"""
           return {{
               'total_calls': len(self.call_history),
               'method_call_counts': self.state['method_calls'].copy(),
               'call_history': self.call_history.copy(),
               'state_snapshot': self.state.copy()
           }}
       
       def reset_mock_state(self):
           """Reset mock state for fresh test scenarios"""
           self.call_history.clear()
           self.state['method_calls'].clear()
           self.state['initialization_count'] = 0
       
       def configure_behavior(self, **configurations):
           """Configure mock behavior for specific test scenarios"""
           self.config.update(configurations)
           self.setup_mock_behavior()
   
   
   @pytest.fixture
   def {sanitize_fixture_name(dep_name)}_mock():
       """Pytest fixture providing configured {dep_name} mock"""
       mock_instance = {sanitize_class_name(dep_name)}Mock()
       
       with patch('{dep_name}', mock_instance):
           yield mock_instance
   
   
   @pytest.fixture
   def {sanitize_fixture_name(dep_name)}_mock_with_errors():
       """Pytest fixture providing {dep_name} mock configured for error scenarios"""
       error_config = {{
           'error_scenarios': [
               {{'method': 'connect', 'error': ConnectionError('Mock connection failed')}},
               {{'method': 'request', 'error': TimeoutError('Mock request timeout')}},
               {{'method': 'authenticate', 'error': AuthenticationError('Mock auth failed')}}
           ]
       }}
       
       mock_instance = {sanitize_class_name(dep_name)}Mock(config=error_config)
       
       with patch('{dep_name}', mock_instance):
           yield mock_instance
   '''
       
       return {
           'mock_class': mock_implementation,
           'dependency_name': dep_name,
           'mock_features': [
               'behavior_simulation',
               'call_tracking',
               'error_scenarios',
               'realistic_return_values',
               'state_management'
           ],
           'pytest_fixtures': generate_pytest_fixtures(dep_name, dep_info),
           'usage_examples': generate_mock_usage_examples(dep_name, dep_info)
       }
   
   
   def create_database_mock(dep_name: str, dep_info: Dict[str, Any], 
                          framework_config: Dict[str, Any]) -> Dict[str, Any]:
       """Create sophisticated database mock with realistic data and behavior"""
       
       database_mock_implementation = f'''
   """
   Advanced Database Mock for {dep_name}
   
   Provides realistic database behavior simulation including:
   - Query result simulation
   - Transaction management
   - Connection pooling simulation
   - Error scenario handling
   """
   
   from unittest.mock import Mock, MagicMock, patch
   from typing import Any, Dict, List, Optional, Union
   import sqlite3
   import json
   import random
   from datetime import datetime, timedelta
   import pytest
   
   
   class DatabaseMockEngine:
       """Advanced database mock engine with realistic behavior"""
       
       def __init__(self, config: Optional[Dict[str, Any]] = None):
           self.config = config or {{}}
           self.mock_data = self._initialize_mock_data()
           self.transaction_state = {{}}
           self.connection_pool = {{}}
           self.query_history = []
       
       def _initialize_mock_data(self) -> Dict[str, List[Dict[str, Any]]]:
           """Initialize realistic mock data for different tables"""
           
           mock_data = {{}}
           
           # Generate data based on detected query patterns
           {generate_mock_data_initialization(dep_info.get('query_patterns', []))}
           
           return mock_data
       
       def execute_query(self, query: str, parameters: Optional[tuple] = None) -> Any:
           """Execute mock query with realistic behavior"""
           
           # Record query execution
           self.query_history.append({{
               'query': query,
               'parameters': parameters,
               'timestamp': datetime.now(),
               'execution_time': random.uniform(0.001, 0.1)  # Simulate execution time
           }})
           
           # Parse query type
           query_type = self._parse_query_type(query)
           
           if query_type == 'SELECT':
               return self._handle_select_query(query, parameters)
           elif query_type == 'INSERT':
               return self._handle_insert_query(query, parameters)
           elif query_type == 'UPDATE':
               return self._handle_update_query(query, parameters)
           elif query_type == 'DELETE':
               return self._handle_delete_query(query, parameters)
           else:
               return self._handle_other_query(query, parameters)
       
       def _handle_select_query(self, query: str, parameters: Optional[tuple]) -> List[Dict[str, Any]]:
           """Handle SELECT query with realistic result generation"""
           
           # Extract table name
           table_name = self._extract_table_name(query)
           
           if table_name in self.mock_data:
               # Apply filters based on WHERE clause
               results = self._apply_query_filters(query, parameters, self.mock_data[table_name])
               
               # Apply LIMIT if present
               limit = self._extract_limit(query)
               if limit:
                   results = results[:limit]
               
               return results
           else:
               # Generate dynamic results for unknown tables
               return self._generate_dynamic_results(query, parameters)
       
       def _handle_insert_query(self, query: str, parameters: Optional[tuple]) -> Dict[str, Any]:
           """Handle INSERT query with data persistence simulation"""
           
           table_name = self._extract_table_name(query)
           
           if table_name not in self.mock_data:
               self.mock_data[table_name] = []
           
           # Extract inserted values
           inserted_values = self._extract_insert_values(query, parameters)
           
           # Add to mock data
           inserted_row = {{
               'id': len(self.mock_data[table_name]) + 1,
               **inserted_values,
               'created_at': datetime.now().isoformat()
           }}
           
           self.mock_data[table_name].append(inserted_row)
           
           return {{
               'lastrowid': inserted_row['id'],
               'rowcount': 1,
               'inserted_row': inserted_row
           }}
       
       def begin_transaction(self) -> str:
           """Begin database transaction simulation"""
           transaction_id = f"txn_{{random.randint(1000, 9999)}}"
           self.transaction_state[transaction_id] = {{
               'status': 'active',
               'start_time': datetime.now(),
               'operations': []
           }}
           return transaction_id
       
       def commit_transaction(self, transaction_id: str) -> bool:
           """Commit database transaction simulation"""
           if transaction_id in self.transaction_state:
               self.transaction_state[transaction_id]['status'] = 'committed'
               self.transaction_state[transaction_id]['commit_time'] = datetime.now()
               return True
           return False
       
       def rollback_transaction(self, transaction_id: str) -> bool:
           """Rollback database transaction simulation"""
           if transaction_id in self.transaction_state:
               self.transaction_state[transaction_id]['status'] = 'rolled_back'
               self.transaction_state[transaction_id]['rollback_time'] = datetime.now()
               
               # Revert operations if needed
               self._revert_transaction_operations(transaction_id)
               return True
           return False
       
       def get_connection(self, connection_string: str = None) -> 'MockConnection':
           """Get mock database connection"""
           connection_id = f"conn_{{random.randint(100, 999)}}"
           connection = MockConnection(connection_id, self)
           self.connection_pool[connection_id] = connection
           return connection
       
       def get_query_statistics(self) -> Dict[str, Any]:
           """Get comprehensive query execution statistics"""
           return {{
               'total_queries': len(self.query_history),
               'query_types': self._analyze_query_types(),
               'execution_times': [q['execution_time'] for q in self.query_history],
               'tables_accessed': self._get_tables_accessed(),
               'transaction_count': len(self.transaction_state)
           }}
   
   
   class MockConnection:
       """Mock database connection with realistic behavior"""
       
       def __init__(self, connection_id: str, engine: DatabaseMockEngine):
           self.connection_id = connection_id
           self.engine = engine
           self.is_closed = False
           self.current_transaction = None
       
       def execute(self, query: str, parameters: Optional[tuple] = None) -> Any:
           """Execute query through connection"""
           if self.is_closed:
               raise Exception("Cannot execute on closed connection")
           
           return self.engine.execute_query(query, parameters)
       
       def cursor(self) -> 'MockCursor':
           """Get cursor for query execution"""
           if self.is_closed:
               raise Exception("Cannot create cursor on closed connection")
           
           return MockCursor(self)
       
       def begin(self) -> str:
           """Begin transaction"""
           if self.current_transaction:
               raise Exception("Transaction already active")
           
           self.current_transaction = self.engine.begin_transaction()
           return self.current_transaction
       
       def commit(self):
           """Commit current transaction"""
           if not self.current_transaction:
               raise Exception("No active transaction")
           
           self.engine.commit_transaction(self.current_transaction)
           self.current_transaction = None
       
       def rollback(self):
           """Rollback current transaction"""
           if not self.current_transaction:
               raise Exception("No active transaction")
           
           self.engine.rollback_transaction(self.current_transaction)
           self.current_transaction = None
       
       def close(self):
           """Close database connection"""
           self.is_closed = True
           if self.current_transaction:
               self.rollback()
   
   
   class MockCursor:
       """Mock database cursor with query execution capabilities"""
       
       def __init__(self, connection: MockConnection):
           self.connection = connection
           self.last_results = None
           self.description = None
       
       def execute(self, query: str, parameters: Optional[tuple] = None) -> Any:
           """Execute query and store results"""
           self.last_results = self.connection.execute(query, parameters)
           
           # Set description for SELECT queries
           if query.strip().upper().startswith('SELECT'):
               self.description = self._generate_description(query)
           
           return self.last_results
       
       def fetchone(self) -> Optional[Dict[str, Any]]:
           """Fetch one result"""
           if isinstance(self.last_results, list) and self.last_results:
               return self.last_results[0]
           return None
       
       def fetchall(self) -> List[Dict[str, Any]]:
           """Fetch all results"""
           if isinstance(self.last_results, list):
               return self.last_results
           return []
       
       def fetchmany(self, size: int = 1) -> List[Dict[str, Any]]:
           """Fetch multiple results"""
           if isinstance(self.last_results, list):
               return self.last_results[:size]
           return []
   
   
   @pytest.fixture
   def database_mock():
       """Pytest fixture providing database mock"""
       mock_engine = DatabaseMockEngine()
       
       with patch('{dep_name}', mock_engine.get_connection):
           yield mock_engine
   
   
   @pytest.fixture
   def database_mock_with_data():
       """Pytest fixture providing database mock with pre-populated data"""
       config = {{
           'preload_data': True,
           'data_size': 'medium'
       }}
       
       mock_engine = DatabaseMockEngine(config)
       
       with patch('{dep_name}', mock_engine.get_connection):
           yield mock_engine
   '''
       
       return {
           'mock_implementation': database_mock_implementation,
           'dependency_name': dep_name,
           'database_type': dep_info.get('database_type', 'generic'),
           'mock_features': [
               'query_execution_simulation',
               'transaction_management',
               'connection_pooling',
               'realistic_data_generation',
               'query_performance_simulation',
               'error_scenario_handling'
           ],
           'data_strategies': generate_data_strategies(dep_info),
           'transaction_patterns': generate_transaction_patterns(dep_info)
       }
   ```

### Phase 3: Test Double Integration and Dependency Injection

4. **Dependency Injection Framework**
   ```python
   def create_dependency_injection_framework(dependency_analysis: Dict[str, Any],
                                           mock_objects: Dict[str, Any]) -> Dict[str, Any]:
       """Create comprehensive dependency injection framework for testing"""
       
       injection_framework = f'''
   """
   Comprehensive Dependency Injection Framework for Testing
   
   Provides flexible dependency injection mechanisms to enable
   isolated unit testing with mock objects and test doubles.
   """
   
   from typing import Any, Dict, List, Optional, Callable, Type, TypeVar, Union
   from functools import wraps
   import inspect
   import pytest
   from unittest.mock import patch, MagicMock
   
   
   T = TypeVar('T')
   
   
   class DependencyRegistry:
       """Central registry for managing test dependencies and their mocks"""
       
       def __init__(self):
           self.dependencies = {{}}
           self.mock_configurations = {{}}
           self.injection_strategies = {{}}
           self.active_patches = []
       
       def register_dependency(self, name: str, dependency_type: Type[T], 
                             mock_factory: Optional[Callable[[], T]] = None,
                             injection_strategy: str = 'patch') -> None:
           """Register a dependency with its mock factory"""
           
           self.dependencies[name] = {{
               'type': dependency_type,
               'mock_factory': mock_factory or (lambda: MagicMock(spec=dependency_type)),
               'injection_strategy': injection_strategy,
               'is_registered': True
           }}
       
       def configure_mock(self, name: str, **configuration) -> None:
           """Configure mock behavior for a registered dependency"""
           if name in self.dependencies:
               self.mock_configurations[name] = configuration
           else:
               raise ValueError(f"Dependency '{{name}}' not registered")
       
       def get_mock(self, name: str) -> Any:
           """Get configured mock for a dependency"""
           if name not in self.dependencies:
               raise ValueError(f"Dependency '{{name}}' not registered")
           
           # Create mock using factory
           mock = self.dependencies[name]['mock_factory']()
           
           # Apply configuration
           if name in self.mock_configurations:
               self._apply_mock_configuration(mock, self.mock_configurations[name])
           
           return mock
       
       def _apply_mock_configuration(self, mock: Any, configuration: Dict[str, Any]) -> None:
           """Apply configuration to mock object"""
           for attr, value in configuration.items():
               if attr == 'return_value':
                   mock.return_value = value
               elif attr == 'side_effect':
                   mock.side_effect = value
               elif attr == 'spec':
                   mock.spec = value
               elif hasattr(mock, attr):
                   setattr(mock, attr, value)
       
       def create_injection_context(self, test_scope: str = 'function') -> 'InjectionContext':
           """Create injection context for test execution"""
           return InjectionContext(self, test_scope)
   
   
   class InjectionContext:
       """Context manager for dependency injection during testing"""
       
       def __init__(self, registry: DependencyRegistry, scope: str = 'function'):
           self.registry = registry
           self.scope = scope
           self.active_patches = []
           self.injected_mocks = {{}}
       
       def __enter__(self):
           """Enter injection context and setup mocks"""
           for name, dep_info in self.registry.dependencies.items():
               mock = self.registry.get_mock(name)
               self.injected_mocks[name] = mock
               
               # Apply injection strategy
               if dep_info['injection_strategy'] == 'patch':
                   patcher = patch(name, mock)
                   self.active_patches.append(patcher)
                   patcher.start()
               elif dep_info['injection_strategy'] == 'attribute':
                   # Will be handled by inject_dependencies decorator
                   pass
           
           return self
       
       def __exit__(self, exc_type, exc_val, exc_tb):
           """Exit injection context and cleanup mocks"""
           for patcher in self.active_patches:
               patcher.stop()
           self.active_patches.clear()
       
       def get_mock(self, name: str) -> Any:
           """Get injected mock by name"""
           return self.injected_mocks.get(name)
       
       def configure_mock(self, name: str, **configuration) -> None:
           """Configure mock behavior within context"""
           if name in self.injected_mocks:
               self.registry._apply_mock_configuration(
                   self.injected_mocks[name], 
                   configuration
               )
   
   
   def inject_dependencies(**dependency_mapping):
       """Decorator for automatic dependency injection into test functions"""
       def decorator(test_func):
           @wraps(test_func)
           def wrapper(*args, **kwargs):
               # Get function signature
               sig = inspect.signature(test_func)
               
               # Inject dependencies based on parameter names
               for param_name, param in sig.parameters.items():
                   if param_name in dependency_mapping:
                       dependency_name = dependency_mapping[param_name]
                       
                       if dependency_name in registry.dependencies:
                           kwargs[param_name] = registry.get_mock(dependency_name)
               
               return test_func(*args, **kwargs)
           return wrapper
       return decorator
   
   
   class MockBuilder:
       """Builder pattern for creating sophisticated mock configurations"""
       
       def __init__(self, mock_type: Type[T]):
           self.mock_type = mock_type
           self.configuration = {{}}
           self.behavior_specs = []
       
       def with_return_value(self, method: str, return_value: Any) -> 'MockBuilder':
           """Configure return value for a method"""
           if 'method_returns' not in self.configuration:
               self.configuration['method_returns'] = {{}}
           self.configuration['method_returns'][method] = return_value
           return self
       
       def with_side_effect(self, method: str, side_effect: Union[Exception, Callable, List]) -> 'MockBuilder':
           """Configure side effect for a method"""
           if 'method_side_effects' not in self.configuration:
               self.configuration['method_side_effects'] = {{}}
           self.configuration['method_side_effects'][method] = side_effect
           return self
       
       def with_property(self, property_name: str, value: Any) -> 'MockBuilder':
           """Configure property value"""
           if 'properties' not in self.configuration:
               self.configuration['properties'] = {{}}
           self.configuration['properties'][property_name] = value
           return self
       
       def with_call_count_limit(self, method: str, max_calls: int) -> 'MockBuilder':
           """Configure maximum call count for a method"""
           if 'call_limits' not in self.configuration:
               self.configuration['call_limits'] = {{}}
           self.configuration['call_limits'][method] = max_calls
           return self
       
       def with_behavior_verification(self, verification_func: Callable) -> 'MockBuilder':
           """Add behavior verification function"""
           self.behavior_specs.append(verification_func)
           return self
       
       def build(self) -> Any:
           """Build configured mock object"""
           mock = MagicMock(spec=self.mock_type)
           
           # Apply method configurations
           if 'method_returns' in self.configuration:
               for method, return_value in self.configuration['method_returns'].items():
                   getattr(mock, method).return_value = return_value
           
           if 'method_side_effects' in self.configuration:
               for method, side_effect in self.configuration['method_side_effects'].items():
                   getattr(mock, method).side_effect = side_effect
           
           # Apply property configurations
           if 'properties' in self.configuration:
               for prop, value in self.configuration['properties'].items():
                   setattr(mock, prop, value)
           
           # Add behavior verification
           if self.behavior_specs:
               mock._behavior_specs = self.behavior_specs
           
           return mock
   
   
   # Global dependency registry
   registry = DependencyRegistry()
   
   
   # Register common dependencies
   {generate_dependency_registrations(dependency_analysis)}
   
   
   @pytest.fixture
   def dependency_injection():
       """Pytest fixture providing dependency injection context"""
       with registry.create_injection_context() as context:
           yield context
   
   
   @pytest.fixture
   def mock_factory():
       """Pytest fixture providing mock builder factory"""
       def create_mock_builder(mock_type: Type[T]) -> MockBuilder:
           return MockBuilder(mock_type)
       return create_mock_builder
   '''
       
       return {
           'injection_framework': injection_framework,
           'features': [
               'dependency_registry',
               'injection_context_management',
               'mock_configuration_builder',
               'automatic_dependency_injection',
               'behavior_verification',
               'pytest_integration'
           ],
           'usage_examples': generate_injection_usage_examples(dependency_analysis)
       }
   ```

### Phase 4: Integration Testing and Behavior Verification

5. **Integration Testing with Mocks**
   ```python
   def create_integration_testing_framework(mock_objects: Dict[str, Any],
                                          injection_framework: Dict[str, Any]) -> Dict[str, Any]:
       """Create comprehensive integration testing framework using mocks"""
       
       integration_framework = f'''
   """
   Integration Testing Framework with Mock Objects
   
   Provides comprehensive integration testing capabilities while
   maintaining isolation through sophisticated mock objects.
   """
   
   import pytest
   from typing import Any, Dict, List, Optional, Callable
   from unittest.mock import patch, MagicMock, call
   import asyncio
   from datetime import datetime, timedelta
   
   
   class IntegrationTestSuite:
       """Comprehensive integration test suite with mock coordination"""
       
       def __init__(self, test_config: Dict[str, Any]):
           self.config = test_config
           self.mock_coordinator = MockCoordinator()
           self.test_scenarios = []
           self.verification_rules = []
       
       def add_test_scenario(self, name: str, scenario_config: Dict[str, Any]) -> None:
           """Add integration test scenario"""
           scenario = {{
               'name': name,
               'description': scenario_config.get('description', ''),
               'setup_steps': scenario_config.get('setup_steps', []),
               'execution_steps': scenario_config.get('execution_steps', []),
               'verification_steps': scenario_config.get('verification_steps', []),
               'cleanup_steps': scenario_config.get('cleanup_steps', []),
               'expected_interactions': scenario_config.get('expected_interactions', []),
               'timeout': scenario_config.get('timeout', 30)
           }}
           self.test_scenarios.append(scenario)
       
       def execute_scenario(self, scenario_name: str) -> Dict[str, Any]:
           """Execute specific integration test scenario"""
           scenario = next((s for s in self.test_scenarios if s['name'] == scenario_name), None)
           if not scenario:
               raise ValueError(f"Scenario '{{scenario_name}}' not found")
           
           results = {{
               'scenario_name': scenario_name,
               'start_time': datetime.now(),
               'setup_results': [],
               'execution_results': [],
               'verification_results': [],
               'mock_interactions': {{}},
               'success': False,
               'error': None
           }}
           
           try:
               # Setup phase
               with self.mock_coordinator.create_coordination_context() as coord_context:
                   # Execute setup steps
                   for step in scenario['setup_steps']:
                       step_result = self._execute_setup_step(step, coord_context)
                       results['setup_results'].append(step_result)
                   
                   # Execute main test steps
                   for step in scenario['execution_steps']:
                       step_result = self._execute_test_step(step, coord_context)
                       results['execution_results'].append(step_result)
                   
                   # Capture mock interactions
                   results['mock_interactions'] = coord_context.get_interaction_summary()
                   
                   # Execute verification steps
                   for step in scenario['verification_steps']:
                       verification_result = self._execute_verification_step(step, coord_context)
                       results['verification_results'].append(verification_result)
                   
                   # Verify expected interactions
                   interaction_verification = self._verify_expected_interactions(
                       scenario['expected_interactions'],
                       results['mock_interactions']
                   )
                   results['interaction_verification'] = interaction_verification
                   
                   results['success'] = all([
                       all(r['success'] for r in results['setup_results']),
                       all(r['success'] for r in results['execution_results']),
                       all(r['success'] for r in results['verification_results']),
                       interaction_verification['all_expectations_met']
                   ])
           
           except Exception as e:
               results['error'] = str(e)
               results['success'] = False
           
           finally:
               results['end_time'] = datetime.now()
               results['duration'] = (results['end_time'] - results['start_time']).total_seconds()
           
           return results
       
       def _execute_setup_step(self, step: Dict[str, Any], coord_context) -> Dict[str, Any]:
           """Execute individual setup step"""
           step_result = {{
               'step_type': 'setup',
               'step_name': step.get('name', 'unnamed_setup'),
               'success': False,
               'output': None,
               'error': None
           }}
           
           try:
               if step['type'] == 'mock_configuration':
                   coord_context.configure_mock(step['mock_name'], **step['configuration'])
                   step_result['success'] = True
               
               elif step['type'] == 'data_preparation':
                   coord_context.prepare_test_data(step['data_config'])
                   step_result['success'] = True
               
               elif step['type'] == 'environment_setup':
                   coord_context.setup_environment(step['environment_config'])
                   step_result['success'] = True
               
               step_result['output'] = "Setup completed successfully"
               
           except Exception as e:
               step_result['error'] = str(e)
           
           return step_result
       
       def _verify_expected_interactions(self, expected_interactions: List[Dict[str, Any]],
                                       actual_interactions: Dict[str, Any]) -> Dict[str, Any]:
           """Verify that expected mock interactions occurred"""
           
           verification_results = {{
               'all_expectations_met': True,
               'individual_results': [],
               'unexpected_interactions': [],
               'missing_interactions': []
           }}
           
           # Check each expected interaction
           for expectation in expected_interactions:
               mock_name = expectation['mock_name']
               method_name = expectation['method_name']
               expected_calls = expectation.get('call_count', 1)
               expected_args = expectation.get('expected_args', None)
               
               actual_calls = actual_interactions.get(mock_name, {{}}).get(method_name, {{}})
               actual_call_count = actual_calls.get('call_count', 0)
               
               result = {{
                   'expectation': expectation,
                   'actual_call_count': actual_call_count,
                   'expected_call_count': expected_calls,
                   'calls_match': actual_call_count == expected_calls,
                   'args_match': True  # Will be updated below
               }}
               
               # Verify call arguments if specified
               if expected_args and actual_calls.get('calls'):
                   args_verification = self._verify_call_arguments(
                       expected_args, 
                       actual_calls['calls']
                   )
                   result['args_match'] = args_verification['all_match']
                   result['args_details'] = args_verification
               
               result['success'] = result['calls_match'] and result['args_match']
               verification_results['individual_results'].append(result)
               
               if not result['success']:
                   verification_results['all_expectations_met'] = False
           
           return verification_results
   
   
   class MockCoordinator:
       """Coordinates multiple mock objects for integration testing"""
       
       def __init__(self):
           self.active_mocks = {{}}
           self.interaction_log = []
           self.coordination_rules = []
       
       def create_coordination_context(self) -> 'CoordinationContext':
           """Create coordination context for mock management"""
           return CoordinationContext(self)
       
       def add_coordination_rule(self, rule: Dict[str, Any]) -> None:
           """Add rule for coordinating mock interactions"""
           self.coordination_rules.append(rule)
       
       def log_interaction(self, mock_name: str, method_name: str, 
                         args: tuple, kwargs: dict, result: Any) -> None:
           """Log mock interaction for verification"""
           interaction = {{
               'timestamp': datetime.now(),
               'mock_name': mock_name,
               'method_name': method_name,
               'args': args,
               'kwargs': kwargs,
               'result': result
           }}
           self.interaction_log.append(interaction)
   
   
   class CoordinationContext:
       """Context for coordinated mock management"""
       
       def __init__(self, coordinator: MockCoordinator):
           self.coordinator = coordinator
           self.context_mocks = {{}}
           self.patches = []
       
       def __enter__(self):
           """Enter coordination context"""
           # Setup coordinated mocks
           {generate_coordinated_mock_setup(mock_objects)}
           return self
       
       def __exit__(self, exc_type, exc_val, exc_tb):
           """Exit coordination context"""
           # Cleanup patches
           for patcher in self.patches:
               patcher.stop()
           self.patches.clear()
       
       def configure_mock(self, mock_name: str, **configuration) -> None:
           """Configure mock within coordination context"""
           if mock_name in self.context_mocks:
               mock = self.context_mocks[mock_name]
               for attr, value in configuration.items():
                   setattr(mock, attr, value)
       
       def get_interaction_summary(self) -> Dict[str, Any]:
           """Get summary of all mock interactions"""
           summary = {{}}
           
           for interaction in self.coordinator.interaction_log:
               mock_name = interaction['mock_name']
               method_name = interaction['method_name']
               
               if mock_name not in summary:
                   summary[mock_name] = {{}}
               
               if method_name not in summary[mock_name]:
                   summary[mock_name][method_name] = {{
                       'call_count': 0,
                       'calls': []
                   }}
               
               summary[mock_name][method_name]['call_count'] += 1
               summary[mock_name][method_name]['calls'].append({{
                   'args': interaction['args'],
                   'kwargs': interaction['kwargs'],
                   'result': interaction['result'],
                   'timestamp': interaction['timestamp']
               }})
           
           return summary
   
   
   # Pytest fixtures for integration testing
   @pytest.fixture
   def integration_test_suite():
       """Pytest fixture providing integration test suite"""
       config = {{
           'timeout': 60,
           'parallel_execution': False,
           'mock_verification': True
       }}
       return IntegrationTestSuite(config)
   
   
   @pytest.fixture
   def mock_coordinator():
       """Pytest fixture providing mock coordinator"""
       return MockCoordinator()
   
   
   # Integration test examples
   {generate_integration_test_examples(mock_objects)}
   '''
       
       return {
           'integration_framework': integration_framework,
           'features': [
               'coordinated_mock_management',
               'integration_scenario_execution',
               'interaction_verification',
               'behavior_validation',
               'comprehensive_reporting'
           ],
           'test_patterns': generate_integration_test_patterns(mock_objects)
       }
   ```

## User Interaction Pattern

### Mock Creation Request
- **User provides**: Target code, dependency requirements, and testing objectives
- **Agent analyzes**: Dependencies and creates comprehensive mock strategy
- **Agent creates**: Sophisticated mock objects with realistic behavior simulation
- **User reviews**: Mock implementations and integration approaches

### Integration Testing Setup
- **Dependency injection**: Automatic injection of mocks into test functions
- **Behavior verification**: Comprehensive interaction and behavior validation
- **Test coordination**: Multiple mock coordination for complex scenarios
- **Performance simulation**: Realistic timing and resource usage simulation

### Continuous Testing
- **Mock maintenance**: Keep mocks synchronized with dependency changes
- **Test evolution**: Evolve test doubles as system complexity grows
- **Coverage analysis**: Ensure comprehensive testing with mock isolation
- **Quality validation**: Verify mock accuracy and test effectiveness

## Quality Gates

-  Comprehensive dependency analysis completed with categorization by type and complexity
-  Mock strategy designed with appropriate frameworks and test double types
-  Sophisticated mock objects created with realistic behavior simulation
-  Database mocks implemented with query execution and transaction simulation
-  API mocks created with request/response patterns and error scenarios
-  Dependency injection framework implemented for seamless test isolation
-  Integration testing framework deployed with coordinated mock management
-  Behavior verification implemented with interaction tracking and validation
-  Mock lifecycle management established with proper setup and cleanup
-  Comprehensive test documentation generated with usage examples and patterns

## Output Standards

### File Locations
- **Mock Objects**: `temp/PYTHON_DEVELOPER/mock_testing/{project_name}_mocks_YYYYMMDD_HHMMSS.py`
- **Injection Framework**: `temp/PYTHON_DEVELOPER/mock_testing/{project_name}_injection_YYYYMMDD_HHMMSS.py`
- **Integration Tests**: `temp/PYTHON_DEVELOPER/mock_testing/{project_name}_integration_tests_YYYYMMDD_HHMMSS.py`
- **Testing Documentation**: `temp/PYTHON_DEVELOPER/mock_testing/{project_name}_mock_guide_YYYYMMDD_HHMMSS.md`

## Integration Points

- **python_test**: Coordinate mock objects with comprehensive unit testing for complete test coverage
- **python_analyze**: Use code analysis to identify dependencies and optimize mock creation strategies
- **python_debug**: Integrate mock debugging capabilities for test troubleshooting and validation
- **python_create**: Ensure mock objects align with actual implementation interfaces and contracts



